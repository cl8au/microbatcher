
<!DOCTYPE html>
<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
		<title>microbatcher: Go Coverage Report</title>
		<style>
			body {
				background: black;
				color: rgb(80, 80, 80);
			}
			body, pre, #legend span {
				font-family: Menlo, monospace;
				font-weight: bold;
			}
			#topbar {
				background: black;
				position: fixed;
				top: 0; left: 0; right: 0;
				height: 42px;
				border-bottom: 1px solid rgb(80, 80, 80);
			}
			#content {
				margin-top: 50px;
			}
			#nav, #legend {
				float: left;
				margin-left: 10px;
			}
			#legend {
				margin-top: 12px;
			}
			#nav {
				margin-top: 10px;
			}
			#legend span {
				margin: 0 5px;
			}
			.cov0 { color: rgb(192, 0, 0) }
.cov1 { color: rgb(128, 128, 128) }
.cov2 { color: rgb(116, 140, 131) }
.cov3 { color: rgb(104, 152, 134) }
.cov4 { color: rgb(92, 164, 137) }
.cov5 { color: rgb(80, 176, 140) }
.cov6 { color: rgb(68, 188, 143) }
.cov7 { color: rgb(56, 200, 146) }
.cov8 { color: rgb(44, 212, 149) }
.cov9 { color: rgb(32, 224, 152) }
.cov10 { color: rgb(20, 236, 155) }

		</style>
	</head>
	<body>
		<div id="topbar">
			<div id="nav">
				<select id="files">
				
				<option value="file0">microbatcher/batcher.go (97.0%)</option>
				
				<option value="file1">microbatcher/pkg/configs/batcher.go (100.0%)</option>
				
				<option value="file2">microbatcher/pkg/types/job.go (100.0%)</option>
				
				<option value="file3">microbatcher/playground/main.go (0.0%)</option>
				
				</select>
			</div>
			<div id="legend">
				<span>not tracked</span>
			
				<span class="cov0">not covered</span>
				<span class="cov8">covered</span>
			
			</div>
		</div>
		<div id="content">
		
		<pre class="file" id="file0" style="display: none">package microbatcher

import (
        "errors"
        "fmt"
        "log/slog"
        "microbatcher/pkg/configs"
        "microbatcher/pkg/processor"
        "microbatcher/pkg/types"
        "sync"
        "time"
)

type microBatcher[I types.JobId, T any] struct {
        name         string
        processor    processor.BatchProcessor[I, T]
        config       configs.BatcherConfig
        results      []*types.JobResult[I, T]
        resultsMutex sync.Mutex
        running      bool
        runningMutex sync.Mutex
        jobs         chan *types.Job[I, T]
        shutdown     chan struct{}
        wg           sync.WaitGroup
}

// NewMicroBatcher creates a new instance of the micro batcher with processor and configurations.
// Each batcher is like a batch worker, it retain it's own job queue and results.
func NewMicroBatcher[I types.JobId, T any](
        name string,
        processor processor.BatchProcessor[I, T],
        config configs.BatcherConfig,
) *microBatcher[I, T] <span class="cov8" title="1">{
        return &amp;microBatcher[I, T]{
                name:      name,
                processor: processor,
                config:    config,
        }
}</span>

// Submit submits a new job to the internal job queue and returns a job result with accepted state.
func (mb *microBatcher[I, T]) Submit(job *types.Job[I, T]) (*types.JobResult[I, T], error) <span class="cov8" title="1">{
        mb.runningMutex.Lock()
        defer mb.runningMutex.Unlock()

        if !mb.running </span><span class="cov8" title="1">{
                return nil, errors.New("invalid submission since batcher is not started")
        }</span>

        <span class="cov8" title="1">select </span>{
        case mb.jobs &lt;- job:<span class="cov8" title="1">
                slog.Info(fmt.Sprintf("%s submits %s", mb.name, job))
                return &amp;types.JobResult[I, T]{ID: job.ID}, nil</span>
        default:<span class="cov8" title="1">
                return nil, errors.New("job queue is full")</span>
        }
}

// Start starts the batch process goroutine which execute custom processor either by either timer
// or size constraint
func (mb *microBatcher[I, T]) Start() error <span class="cov8" title="1">{
        mb.runningMutex.Lock()
        defer mb.runningMutex.Unlock()

        if mb.running </span><span class="cov8" title="1">{
                return errors.New("batcher is started already")
        }</span>

        <span class="cov8" title="1">slog.Info(fmt.Sprintf("%s starts", mb.name))

        mb.running = true
        // init channels here. This is helpful to
        // let batcher can be shutdown and start again
        mb.jobs = make(chan *types.Job[I, T], mb.config.GetJobQueueSize())
        mb.shutdown = make(chan struct{})
        mb.results = nil

        mb.wg.Add(1)
        go mb.execute()
        return nil</span>
}

// GetCurrentResults returns the all current of processed jobs
func (mb *microBatcher[I, T]) GetCurrentResults() []*types.JobResult[I, T] <span class="cov8" title="1">{
        mb.resultsMutex.Lock()
        defer mb.resultsMutex.Unlock()

        clonedResults := make([]*types.JobResult[I, T], len(mb.results))
        copy(clonedResults, mb.results)
        return clonedResults
}</span>

func (mb *microBatcher[I, T]) Shutdown() error <span class="cov8" title="1">{
        mb.runningMutex.Lock()
        defer mb.runningMutex.Unlock()

        if !mb.running </span><span class="cov8" title="1">{
                return errors.New("invalid shutdown since batcher is stopped")
        }</span>
        <span class="cov8" title="1">slog.Info(fmt.Sprintf("%s starts shutting down", mb.name))
        // send shutdown signal via channel
        close(mb.shutdown)
        // wait for the process goroutine to be finished
        mb.wg.Wait()
        // close job channels
        close(mb.jobs)

        mb.running = false
        slog.Info(fmt.Sprintf("%s shuts down", mb.name))

        return nil</span>
}

func (mb *microBatcher[I, T]) execute() <span class="cov8" title="1">{
        defer mb.wg.Done()

        timer := time.NewTimer(mb.config.GetBatchProcessFrequency())
        defer timer.Stop()

        // rely on local batch job slice to monitor the in-taking batch size
        var batchJobs []*types.Job[I, T]
        for </span><span class="cov8" title="1">{
                select </span>{
                case job := &lt;-mb.jobs:<span class="cov8" title="1">
                        batchJobs = append(batchJobs, job)
                        // invoke custom processor when batch size is reached
                        if len(batchJobs) &gt;= mb.config.GetBatchProcessSize() </span><span class="cov8" title="1">{
                                mb.processBatch(batchJobs, timer)
                                batchJobs = nil
                        }</span>
                case &lt;-timer.C:<span class="cov8" title="1">
                        if len(batchJobs) &gt; 0 </span><span class="cov8" title="1">{
                                // Process batch on timer trigger
                                mb.processBatch(batchJobs, timer)
                                batchJobs = nil
                        }</span>
                case &lt;-mb.shutdown:<span class="cov8" title="1">
                        // handle shutdown case
                        batchJobs = mb.drainQueue(batchJobs)
                        if len(batchJobs) &gt; 0 </span><span class="cov0" title="0">{
                                mb.processBatch(batchJobs, timer)
                        }</span>
                        <span class="cov8" title="1">return</span>
                }
        }
}

func (mb *microBatcher[I, T]) processBatch(batchJobs []*types.Job[I, T], timer *time.Timer) <span class="cov8" title="1">{
        // need to stop and reset the timer since the batch process
        timer.Stop()
        defer timer.Reset(mb.config.GetBatchProcessFrequency())

        // call custom processor to process the batch jobs
        slog.Info(fmt.Sprintf("%s starts batch process", mb.name))
        results := mb.processor.Process(batchJobs)

        // cache this batch results in the batcher
        mb.recordResults(results)
}</span>

// The mutex here since the GetCurrentResults function. Read and write in different goroutine and GetCurrentResults
// can be called by external anytime they need. Therefore, the mutex of results is needed here.
func (mb *microBatcher[I, T]) recordResults(newResults []*types.JobResult[I, T]) <span class="cov8" title="1">{
        mb.resultsMutex.Lock()
        defer mb.resultsMutex.Unlock()

        mb.results = append(mb.results, newResults...)
}</span>

func (mb *microBatcher[I, T]) drainQueue(batchJobs []*types.Job[I, T]) []*types.Job[I, T] <span class="cov8" title="1">{
        for </span><span class="cov8" title="1">{
                select </span>{
                case job := &lt;-mb.jobs:<span class="cov0" title="0">
                        batchJobs = append(batchJobs, job)</span>
                default:<span class="cov8" title="1">
                        // no more to drain
                        return batchJobs</span>
                }
        }
}
</pre>
		
		<pre class="file" id="file1" style="display: none">package configs

import (
        "errors"
        "time"
)

const DEFAULT_QUEUE_SIZE = 100
const DEFAULT_BATCH_PROCESS_SIZE = 10
const DEFAULT_BATCH_PROCESS_FREQUENCY_IN_MILLISECOND = 100
const QUEUE_FACTOR = 2

type BatcherConfig struct {
        jobQueueSize          int
        batchProcessSize      int
        batchProcessFrequency time.Duration
}

// NewDefaultConfig creates and returns a new batcher config with default values.
func NewDefaultConfig() BatcherConfig <span class="cov8" title="1">{
        return BatcherConfig{
                jobQueueSize:          DEFAULT_QUEUE_SIZE,
                batchProcessSize:      DEFAULT_BATCH_PROCESS_SIZE,
                batchProcessFrequency: DEFAULT_BATCH_PROCESS_FREQUENCY_IN_MILLISECOND * time.Millisecond,
        }
}</span>

// NewCustomConfig creates and returns a new batcher with custom values.
func NewCustomConfig(
        jobQueueSize int,
        batchProcessSize int,
        batchProcessFrequency time.Duration,
) (BatcherConfig, error) <span class="cov8" title="1">{
        if jobQueueSize &lt; 1 || batchProcessSize &lt; 1 || batchProcessFrequency &lt;= 0 </span><span class="cov8" title="1">{
                return BatcherConfig{}, errors.New("jobQueueSize, batchProcessSize, and batchProcessFrequency must be positive")
        }</span>

        <span class="cov8" title="1">if jobQueueSize &lt; batchProcessSize*QUEUE_FACTOR </span><span class="cov8" title="1">{
                return BatcherConfig{}, errors.New("job queue size must be at least twice the batch process size")
        }</span>

        <span class="cov8" title="1">return BatcherConfig{
                jobQueueSize:          jobQueueSize,
                batchProcessSize:      batchProcessSize,
                batchProcessFrequency: batchProcessFrequency,
        }, nil</span>
}

// GetJobQueueSize returns the job queue size.
func (b *BatcherConfig) GetJobQueueSize() int <span class="cov8" title="1">{
        return b.jobQueueSize
}</span>

// GetBatchProcessSize returns the batch process size.
func (b *BatcherConfig) GetBatchProcessSize() int <span class="cov8" title="1">{
        return b.batchProcessSize
}</span>

// GetBatchProcessFrequency returns the batch process frequency.
func (b *BatcherConfig) GetBatchProcessFrequency() time.Duration <span class="cov8" title="1">{
        return b.batchProcessFrequency
}</span>
</pre>
		
		<pre class="file" id="file2" style="display: none">package types

import "fmt"

type JobId interface {
        ~int | ~string
}

type Job[I JobId, T any] struct {
        ID   I
        Data T
}

func (j *Job[I, T]) String() string <span class="cov8" title="1">{
        return fmt.Sprintf("job: id=%v", j.ID)
}</span>

type JobResult[I JobId, T any] struct {
        ID     I
        Data   T
        Errors error
}

func (jr *JobResult[I, T]) String() string <span class="cov8" title="1">{
        return fmt.Sprintf("job result: id=%v", jr.ID)
}</span>
</pre>
		
		<pre class="file" id="file3" style="display: none">package main

import (
        "fmt"
        "log/slog"
        "microbatcher"
        "microbatcher/pkg/configs"
        "microbatcher/pkg/types"
        "sync"
)

type PlaygroundMicroBatcherProcess struct{}

func (pm *PlaygroundMicroBatcherProcess) Process(jobs []*types.Job[int, string]) []*types.JobResult[int, string] <span class="cov0" title="0">{
        results := make([]*types.JobResult[int, string], 0)
        for _, job := range jobs </span><span class="cov0" title="0">{
                slog.Info(fmt.Sprintf("playground is processing job %d", job.ID))
                results = append(results, &amp;types.JobResult[int, string]{
                        ID:   job.ID,
                        Data: fmt.Sprintf("processed job %d", job.ID),
                })
        }</span>
        <span class="cov0" title="0">return results</span>
}

func main() <span class="cov0" title="0">{
        // create two batchers
        processor := &amp;PlaygroundMicroBatcherProcess{}
        batcher01 := microbatcher.NewMicroBatcher("batcher01", processor, configs.NewDefaultConfig())
        batcher02 := microbatcher.NewMicroBatcher("batcher02", processor, configs.NewDefaultConfig())

        for k := 0; k &lt; 3; k++ </span><span class="cov0" title="0">{
                _ = batcher01.Start()
                _ = batcher02.Start()

                var wg sync.WaitGroup

                wg.Add(1)
                go func() </span><span class="cov0" title="0">{
                        defer wg.Done()
                        for i := 0; i &lt; 1000; i++ </span><span class="cov0" title="0">{
                                _, _ = batcher01.Submit(&amp;types.Job[int, string]{
                                        ID:   i,
                                        Data: fmt.Sprintf("round %d - job %d", k, i),
                                })
                        }</span>
                }()

                <span class="cov0" title="0">wg.Add(1)
                go func() </span><span class="cov0" title="0">{
                        defer wg.Done()
                        for i := 0; i &lt; 500; i++ </span><span class="cov0" title="0">{
                                _, _ = batcher02.Submit(&amp;types.Job[int, string]{
                                        ID:   i,
                                        Data: fmt.Sprintf("round %d - job %d", k, i),
                                })
                        }</span>
                }()

                <span class="cov0" title="0">wg.Wait()

                _ = batcher01.Shutdown()
                _ = batcher02.Shutdown()

                results := batcher01.GetCurrentResults()
                for _, result := range results </span><span class="cov0" title="0">{
                        slog.Info(fmt.Sprintf("round %d - batch01 result: %s with data: %s\n", k, result, result.Data))
                }</span>
                <span class="cov0" title="0">slog.Info(fmt.Sprintf("round %d - batch01 result size: %d\n", k, len(results)))
                results = batcher02.GetCurrentResults()
                for _, result := range results </span><span class="cov0" title="0">{
                        slog.Info(fmt.Sprintf("round %d - batch02 result: %s with data: %s\n", k, result, result.Data))
                }</span>
                <span class="cov0" title="0">slog.Info(fmt.Sprintf("round %d - batch02 result size: %d\n", k, len(results)))</span>
        }
}
</pre>
		
		</div>
	</body>
	<script>
	(function() {
		var files = document.getElementById('files');
		var visible;
		files.addEventListener('change', onChange, false);
		function select(part) {
			if (visible)
				visible.style.display = 'none';
			visible = document.getElementById(part);
			if (!visible)
				return;
			files.value = part;
			visible.style.display = 'block';
			location.hash = part;
		}
		function onChange() {
			select(files.value);
			window.scrollTo(0, 0);
		}
		if (location.hash != "") {
			select(location.hash.substr(1));
		}
		if (!visible) {
			select("file0");
		}
	})();
	</script>
</html>
